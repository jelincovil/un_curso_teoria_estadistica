{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e50aa51",
   "metadata": {},
   "source": [
    "# Convexidad del Modelo Logístico\n",
    "\n",
    "Demostración práctica de la ventaja de la convexidad (Proposición 2.1) usando el dataset de cáncer de mama de *scikit‑learn*. Se compara la estabilidad de la regresión logística (convexa) con una red neuronal MLP (no convexa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64730e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar y simplificar dataset (2 features para visualización)\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "X_raw = df[data.feature_names].values[:, :2]   # sólo 2 primeras columnas\n",
    "y = df[\"target\"].values\n",
    "\n",
    "# Estandarizar + intercepto\n",
    "X_scaled = StandardScaler().fit_transform(X_raw)\n",
    "X = np.column_stack([np.ones_like(y), X_scaled])  # (n,3)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# --------- Funciones logísticas (convexas) -------------\n",
    "def nll(beta, X, y):\n",
    "    z = X @ beta\n",
    "    return np.sum(np.logaddexp(0, z) - y * z)\n",
    "\n",
    "def grad_nll(beta, X, y):\n",
    "    z = X @ beta\n",
    "    p = 1 / (1 + np.exp(-z))\n",
    "    return X.T @ (p - y)\n",
    "\n",
    "def gradient_descent(beta0, X, y, lr=0.01, max_iter=10000, tol=1e-6):\n",
    "    beta = beta0.copy()\n",
    "    for _ in range(max_iter):\n",
    "        g = grad_nll(beta, X, y)\n",
    "        beta_new = beta - lr * g\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "        beta = beta_new\n",
    "    return beta\n",
    "\n",
    "betas = []\n",
    "for seed in range(5):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    beta0 = rng.standard_normal(X.shape[1])\n",
    "    betas.append(gradient_descent(beta0, X_train, y_train))\n",
    "\n",
    "betas = np.vstack(betas)\n",
    "beta_ref = betas[0]\n",
    "coef_diff = np.linalg.norm(betas - beta_ref, axis=1)\n",
    "\n",
    "def predict(beta, X):\n",
    "    return (X @ beta > 0).astype(int)\n",
    "\n",
    "acc_log = [accuracy_score(y_test, predict(b, X_test)) for b in betas]\n",
    "\n",
    "logistic_df = pd.DataFrame({\n",
    "    \"seed\": range(5),\n",
    "    \"coef_intercept\": betas[:, 0],\n",
    "    \"coef_x1\": betas[:, 1],\n",
    "    \"coef_x2\": betas[:, 2],\n",
    "    \"||β − β₀||₂\": coef_diff,\n",
    "    \"test_accuracy\": acc_log,\n",
    "})\n",
    "logistic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Modelo no convexo: MLP -------------\n",
    "mlp_acc = []\n",
    "for seed in range(5):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(5,), max_iter=600, random_state=seed)\n",
    "    clf.fit(X_train[:, 1:], y_train)  # sin columna de intercepto\n",
    "    mlp_acc.append(accuracy_score(y_test, clf.predict(X_test[:, 1:])))\n",
    "\n",
    "mlp_df = pd.DataFrame({\n",
    "    \"seed\": range(5),\n",
    "    \"MLP_test_accuracy\": mlp_acc,\n",
    "})\n",
    "mlp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554886f",
   "metadata": {},
   "source": [
    "## Interpretación\n",
    "\n",
    "* **Regresión logística (convexa)**  \n",
    "  - Las 5 corridas convergen al **mismo mínimo global** (‖β − β₀‖≈0).  \n",
    "  - Accuracy de test idéntica → entrenamiento estable e independiente de la semilla.\n",
    "\n",
    "* **MLP (no convexa)**  \n",
    "  - Accuracy varía entre semillas → múltiples mínimos locales, sensibilidad a la inicialización.\n",
    "\n",
    "Esta evidencia práctica conecta la *convexidad* de la familia exponencial (Proposición 2.1) con beneficios reales en ciencia de datos: **unicidad del MLE, reproducibilidad y optimización fiable**."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
